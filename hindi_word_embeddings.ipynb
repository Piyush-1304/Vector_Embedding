{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Install required libraries\n",
    "!pip install torch sentencepiece pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate and save Hindi dataset (80 rows x 5 columns)\n",
    "import csv\n",
    "\n",
    "data = [\n",
    "    (\"भारत ने ऑस्ट्रेलिया को पाँच विकेट से हराया।\", \"खेल\", \"सकारात्मक\", 1),\n",
    "    (\"रोहित शर्मा ने शतक लगाते हुए टीम को जीत दिलाई।\", \"खेल\", \"सकारात्मक\", 1),\n",
    "    (\"भारतीय हॉकी टीम ने स्वर्ण पदक जीता।\", \"खेल\", \"सकारात्मक\", 1),\n",
    "    (\"पीवी सिंधु ने बैडमिंटन में रजत पदक हासिल किया।\", \"खेल\", \"सकारात्मक\", 1),\n",
    "    (\"क्रिकेट विश्व कप में भारत सेमीफाइनल में पहुँचा।\", \"खेल\", \"सकारात्मक\", 1),\n",
    "    (\"नीरज चोपड़ा ने भाला फेंक में नया रिकॉर्ड बनाया।\", \"खेल\", \"सकारात्मक\", 1),\n",
    "    (\"भारत को फुटबॉल में करारी हार का सामना करना पड़ा।\", \"खेल\", \"नकारात्मक\", 0),\n",
    "    (\"टेनिस टूर्नामेंट में भारतीय खिलाड़ी पहले दौर में बाहर हुए।\", \"खेल\", \"नकारात्मक\", 0),\n",
    "    (\"कबड्डी विश्व कप में भारत उपविजेता रहा।\", \"खेल\", \"तटस्थ\", 2),\n",
    "    (\"मैच बारिश के कारण रद्द कर दिया गया।\", \"खेल\", \"तटस्थ\", 2),\n",
    "    (\"सरकार ने नई शिक्षा नीति लागू करने की घोषणा की।\", \"राजनीति\", \"सकारात्मक\", 1),\n",
    "    (\"संसद में नया बजट पेश किया गया।\", \"राजनीति\", \"तटस्थ\", 2),\n",
    "    (\"चुनाव आयोग ने मतदान की तारीख की घोषणा की।\", \"राजनीति\", \"तटस्थ\", 2),\n",
    "    (\"प्रधानमंत्री ने विदेश यात्रा के दौरान कई समझौते किए।\", \"राजनीति\", \"सकारात्मक\", 1),\n",
    "    (\"विपक्ष ने सरकार की नीतियों की आलोचना की।\", \"राजनीति\", \"नकारात्मक\", 0),\n",
    "    (\"राज्य सरकार ने किसानों के लिए राहत पैकेज दिया।\", \"राजनीति\", \"सकारात्मक\", 1),\n",
    "    (\"देश में महंगाई दर में वृद्धि दर्ज की गई।\", \"राजनीति\", \"नकारात्मक\", 0),\n",
    "    (\"नए कानून को संसद ने मंजूरी दी।\", \"राजनीति\", \"तटस्थ\", 2),\n",
    "    (\"मुख्यमंत्री ने जनता से सीधे संवाद किया।\", \"राजनीति\", \"सकारात्मक\", 1),\n",
    "    (\"राजनीतिक दलों के बीच गठबंधन की चर्चा शुरू हुई।\", \"राजनीति\", \"तटस्थ\", 2),\n",
    "    (\"सरकारी स्कूलों में डिजिटल क्लासरूम स्थापित किए जाएंगे।\", \"शिक्षा\", \"सकारात्मक\", 1),\n",
    "    (\"बोर्ड परीक्षा के परिणाम घोषित हुए, छात्रों ने उत्कृष्ट प्रदर्शन किया।\", \"शिक्षा\", \"सकारात्मक\", 1),\n",
    "    (\"IIT प्रवेश परीक्षा में इस वर्ष रिकॉर्ड आवेदन आए।\", \"शिक्षा\", \"तटस्थ\", 2),\n",
    "    (\"विश्वविद्यालय में नए पाठ्यक्रम शुरू किए गए।\", \"शिक्षा\", \"सकारात्मक\", 1),\n",
    "    (\"ग्रामीण क्षेत्रों में साक्षरता दर बढ़ी है।\", \"शिक्षा\", \"सकारात्मक\", 1),\n",
    "    (\"परीक्षा में नकल के मामले सामने आए।\", \"शिक्षा\", \"नकारात्मक\", 0),\n",
    "    (\"छात्रवृत्ति योजना से हजारों छात्रों को लाभ मिला।\", \"शिक्षा\", \"सकारात्मक\", 1),\n",
    "    (\"शिक्षक भर्ती परीक्षा का परिणाम जारी किया गया।\", \"शिक्षा\", \"तटस्थ\", 2),\n",
    "    (\"ऑनलाइन शिक्षा में तकनीकी खामियाँ सामने आईं।\", \"शिक्षा\", \"नकारात्मक\", 0),\n",
    "    (\"सरकार ने मिड-डे मील योजना का विस्तार किया।\", \"शिक्षा\", \"सकारात्मक\", 1),\n",
    "    (\"सरकार ने मुफ्त टीकाकरण अभियान शुरू किया।\", \"स्वास्थ्य\", \"सकारात्मक\", 1),\n",
    "    (\"नई दवा के परीक्षण में सफलता मिली।\", \"स्वास्थ्य\", \"सकारात्मक\", 1),\n",
    "    (\"देश में डेंगू के मामले तेजी से बढ़ रहे हैं।\", \"स्वास्थ्य\", \"नकारात्मक\", 0),\n",
    "    (\"आयुष्मान भारत योजना से लाखों मरीजों को फायदा हुआ।\", \"स्वास्थ्य\", \"सकारात्मक\", 1),\n",
    "    (\"अस्पताल में बेड की कमी के कारण मरीजों को परेशानी हुई।\", \"स्वास्थ्य\", \"नकारात्मक\", 0),\n",
    "    (\"योग और आयुर्वेद की वैश्विक मांग बढ़ी है।\", \"स्वास्थ्य\", \"सकारात्मक\", 1),\n",
    "    (\"नई स्वास्थ्य नीति का मसौदा तैयार किया गया।\", \"स्वास्थ्य\", \"तटस्थ\", 2),\n",
    "    (\"कैंसर के इलाज में नई तकनीक ने उम्मीद जगाई।\", \"स्वास्थ्य\", \"सकारात्मक\", 1),\n",
    "    (\"वायु प्रदूषण के कारण सांस की बीमारियाँ बढ़ी हैं।\", \"स्वास्थ्य\", \"नकारात्मक\", 0),\n",
    "    (\"स्वास्थ्य विभाग ने जागरूकता अभियान चलाया।\", \"स्वास्थ्य\", \"सकारात्मक\", 1),\n",
    "    (\"भारत ने स्वदेशी 5G तकनीक विकसित की।\", \"प्रौद्योगिकी\", \"सकारात्मक\", 1),\n",
    "    (\"ISRO ने सफलतापूर्वक उपग्रह लॉन्च किया।\", \"प्रौद्योगिकी\", \"सकारात्मक\", 1),\n",
    "    (\"साइबर हमलों में वृद्धि देखी जा रही है।\", \"प्रौद्योगिकी\", \"नकारात्मक\", 0),\n",
    "    (\"आर्टिफिशियल इंटेलिजेंस से रोजगार के नए अवसर आए।\", \"प्रौद्योगिकी\", \"सकारात्मक\", 1),\n",
    "    (\"डेटा प्राइवेसी बिल संसद में पेश किया गया।\", \"प्रौद्योगिकी\", \"तटस्थ\", 2),\n",
    "    (\"स्टार्टअप इंडिया ने नए रिकॉर्ड निवेश आकर्षित किए।\", \"प्रौद्योगिकी\", \"सकारात्मक\", 1),\n",
    "    (\"मोबाइल इंटरनेट की गति में सुधार आया है।\", \"प्रौद्योगिकी\", \"सकारात्मक\", 1),\n",
    "    (\"सोशल मीडिया पर फर्जी खबरों का प्रसार चिंताजनक।\", \"प्रौद्योगिकी\", \"नकारात्मक\", 0),\n",
    "    (\"भारतीय IT कंपनियों ने वैश्विक बाजार में धूम मचाई।\", \"प्रौद्योगिकी\", \"सकारात्मक\", 1),\n",
    "    (\"ड्रोन तकनीक का कृषि में उपयोग बढ़ा।\", \"प्रौद्योगिकी\", \"सकारात्मक\", 1),\n",
    "    (\"बॉलीवुड फिल्म ने पहले हफ्ते में 200 करोड़ की कमाई की।\", \"मनोरंजन\", \"सकारात्मक\", 1),\n",
    "    (\"OTT प्लेटफॉर्म पर हिंदी कंटेंट की मांग बढ़ी।\", \"मनोरंजन\", \"सकारात्मक\", 1),\n",
    "    (\"फिल्म समारोह में भारतीय फिल्म को पुरस्कार मिला।\", \"मनोरंजन\", \"सकारात्मक\", 1),\n",
    "    (\"प्रसिद्ध अभिनेता ने सामाजिक कार्य में भाग लिया।\", \"मनोरंजन\", \"सकारात्मक\", 1),\n",
    "    (\"संगीत एल्बम ने करोड़ों स्ट्रीम का आँकड़ा पार किया।\", \"मनोरंजन\", \"सकारात्मक\", 1),\n",
    "    (\"फिल्म की शूटिंग के दौरान हादसा हुआ।\", \"मनोरंजन\", \"नकारात्मक\", 0),\n",
    "    (\"टेलीविजन रेटिंग में नाटकीय बदलाव देखा गया।\", \"मनोरंजन\", \"तटस्थ\", 2),\n",
    "    (\"कॉमेडी शो ने दर्शकों में खूब लोकप्रियता पाई।\", \"मनोरंजन\", \"सकारात्मक\", 1),\n",
    "    (\"पुरानी फिल्मों को रीमेक किए जाने की लहर चली।\", \"मनोरंजन\", \"तटस्थ\", 2),\n",
    "    (\"नई वेब सीरीज को दर्शकों ने खूब सराहा।\", \"मनोरंजन\", \"सकारात्मक\", 1),\n",
    "    (\"शेयर बाजार ने नई ऊँचाई छुई।\", \"व्यापार\", \"सकारात्मक\", 1),\n",
    "    (\"भारत की GDP वृद्धि दर 7% रही।\", \"व्यापार\", \"सकारात्मक\", 1),\n",
    "    (\"नए FDI नियमों से विदेशी निवेश बढ़ा।\", \"व्यापार\", \"सकारात्मक\", 1),\n",
    "    (\"कच्चे तेल की कीमतों में उछाल से महंगाई बढ़ी।\", \"व्यापार\", \"नकारात्मक\", 0),\n",
    "    (\"छोटे और मध्यम उद्योगों को सरकारी सहायता मिली।\", \"व्यापार\", \"सकारात्मक\", 1),\n",
    "    (\"रुपए की कीमत में गिरावट आई।\", \"व्यापार\", \"नकारात्मक\", 0),\n",
    "    (\"भारतीय कंपनी ने विदेशी बाजार में कदम रखा।\", \"व्यापार\", \"सकारात्मक\", 1),\n",
    "    (\"व्यापार घाटे में मामूली कमी दर्ज की गई।\", \"व्यापार\", \"तटस्थ\", 2),\n",
    "    (\"स्टार्टअप इकोसिस्टम में नए यूनिकॉर्न उभरे।\", \"व्यापार\", \"सकारात्मक\", 1),\n",
    "    (\"बाजार में मंदी के संकेत दिखे।\", \"व्यापार\", \"नकारात्मक\", 0),\n",
    "    (\"भारतीय वैज्ञानिकों ने नई प्रजाति की खोज की।\", \"विज्ञान\", \"सकारात्मक\", 1),\n",
    "    (\"चंद्रयान मिशन ने अहम डेटा भेजा।\", \"विज्ञान\", \"सकारात्मक\", 1),\n",
    "    (\"जलवायु परिवर्तन पर नई रिपोर्ट जारी हुई।\", \"विज्ञान\", \"तटस्थ\", 2),\n",
    "    (\"अंतरिक्ष अनुसंधान में नया मील का पत्थर हासिल हुआ।\", \"विज्ञान\", \"सकारात्मक\", 1),\n",
    "    (\"ग्लेशियर पिघलने की दर चिंताजनक स्तर पर पहुँची।\", \"विज्ञान\", \"नकारात्मक\", 0),\n",
    "    (\"नई ऊर्जा स्रोत की खोज में सफलता मिली।\", \"विज्ञान\", \"सकारात्मक\", 1),\n",
    "    (\"भूकंप की भविष्यवाणी के लिए नई तकनीक विकसित।\", \"विज्ञान\", \"सकारात्मक\", 1),\n",
    "    (\"समुद्री प्रदूषण पर शोध रिपोर्ट सामने आई।\", \"विज्ञान\", \"नकारात्मक\", 0),\n",
    "    (\"भारतीय शोधकर्ताओं का शोध अंतरराष्ट्रीय जर्नल में प्रकाशित।\", \"विज्ञान\", \"सकारात्मक\", 1),\n",
    "    (\"सौरमंडल के बारे में नई जानकारी मिली।\", \"विज्ञान\", \"सकारात्मक\", 1),\n",
    "]\n",
    "\n",
    "with open(\"hindi_dataset.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"id\", \"text\", \"category\", \"sentiment\", \"label\"])\n",
    "    for i, (text, category, sentiment, label) in enumerate(data, 1):\n",
    "        writer.writerow([i, text, category, sentiment, label])\n",
    "\n",
    "print(f\"Dataset saved: hindi_dataset.csv  ({len(data)} rows x 5 columns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and explore the dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hindi_dataset.csv\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "display(df.head(10))\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(df[\"category\"].value_counts())\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build raw Hindi text corpus from all sentences\n",
    "raw_text = \" \".join(df[\"text\"].tolist())\n",
    "print(f\"Total characters : {len(raw_text):,}\")\n",
    "print(f\"Total sentences  : {len(df)}\")\n",
    "print(f\"\\nSample:\\n{raw_text[:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Hindi tokenization using Unicode Devanagari regex\n",
    "import re\n",
    "\n",
    "def hindi_tokenize(text):\n",
    "    return re.findall(r'[\\u0900-\\u097F]+|[A-Za-z0-9]+|[।,!?]', text)\n",
    "\n",
    "sample = df[\"text\"][0]\n",
    "tokens = hindi_tokenize(sample)\n",
    "print(f\"Original : {sample}\")\n",
    "print(f\"Tokens   : {tokens}\")\n",
    "print(f\"Count    : {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build vocabulary with special tokens <PAD> <UNK> <BOS> <EOS>\n",
    "all_tokens = []\n",
    "for text in df[\"text\"]:\n",
    "    all_tokens.extend(hindi_tokenize(text))\n",
    "\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1, \"<BOS>\": 2, \"<EOS>\": 3}\n",
    "for idx, token in enumerate(sorted(set(all_tokens)), start=4):\n",
    "    vocab[token] = idx\n",
    "id_to_token = {v: k for k, v in vocab.items()}\n",
    "\n",
    "print(f\"Vocabulary size : {len(vocab)}\")\n",
    "print(f\"Total tokens    : {len(all_tokens)}\")\n",
    "print(\"\\nSample vocab:\")\n",
    "for token, idx in list(vocab.items())[4:14]:\n",
    "    print(f\"  '{token}' -> {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Encode and decode Hindi sentences using the vocabulary\n",
    "def encode(text, vocab):\n",
    "    return [vocab.get(t, vocab[\"<UNK>\"]) for t in hindi_tokenize(text)]\n",
    "\n",
    "def decode(ids, id_to_token):\n",
    "    return \" \".join([id_to_token.get(i, \"<UNK>\") for i in ids])\n",
    "\n",
    "sample_text = df[\"text\"][5]\n",
    "encoded = encode(sample_text, vocab)\n",
    "print(f\"Original : {sample_text}\")\n",
    "print(f\"Encoded  : {encoded}\")\n",
    "print(f\"Decoded  : {decode(encoded, id_to_token)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train SentencePiece BPE tokenizer on the Hindi corpus\n",
    "import sentencepiece as spm\n",
    "\n",
    "with open(\"hindi_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(df[\"text\"].tolist()))\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"hindi_corpus.txt\",\n",
    "    model_prefix=\"hindi_bpe\",\n",
    "    vocab_size=500,\n",
    "    character_coverage=1.0,\n",
    "    model_type=\"bpe\",\n",
    "    pad_id=0, unk_id=1, bos_id=2, eos_id=3\n",
    ")\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"hindi_bpe.model\")\n",
    "print(f\"BPE tokenizer trained | vocab size: {sp.get_piece_size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Encode Hindi text with BPE and show subword pieces\n",
    "sample = df[\"text\"][0]\n",
    "pieces = sp.encode(sample, out_type=str)\n",
    "ids    = sp.encode(sample, out_type=int)\n",
    "\n",
    "print(f\"Original  : {sample}\")\n",
    "print(f\"BPE pieces: {pieces}\")\n",
    "print(f\"BPE IDs   : {ids}\")\n",
    "print(f\"Decoded   : {sp.decode(ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Build padded token ID tensor for all 80 sentences\n",
    "import torch\n",
    "\n",
    "MAX_LEN = 20\n",
    "\n",
    "def encode_and_pad(text, sp, max_len):\n",
    "    ids = sp.encode(text, out_type=int)[:max_len]\n",
    "    ids += [0] * (max_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "token_tensor = torch.tensor(\n",
    "    [encode_and_pad(t, sp, MAX_LEN) for t in df[\"text\"]], dtype=torch.long\n",
    ")\n",
    "print(f\"Token tensor shape : {token_tensor.shape}  -> (80 sentences x 20 tokens)\")\n",
    "print(f\"Sample row         : {token_tensor[0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Token embedding layer for Hindi BPE vocabulary\n",
    "VOCAB_SIZE = sp.get_piece_size()\n",
    "EMB_DIM    = 64\n",
    "\n",
    "torch.manual_seed(42)\n",
    "token_embedding_layer = torch.nn.Embedding(VOCAB_SIZE, EMB_DIM, padding_idx=0)\n",
    "token_embeddings = token_embedding_layer(token_tensor)\n",
    "print(f\"Token embeddings shape : {token_embeddings.shape}  -> (80 x 20 x 64)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Positional embedding layer for sequence positions\n",
    "pos_embedding_layer = torch.nn.Embedding(MAX_LEN, EMB_DIM)\n",
    "positions = torch.arange(MAX_LEN).unsqueeze(0).expand(len(df), -1)\n",
    "pos_embeddings = pos_embedding_layer(positions)\n",
    "print(f\"Positional embeddings shape : {pos_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Final input embeddings = token embeddings + positional embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(f\"Token embeddings        : {token_embeddings.shape}\")\n",
    "print(f\"Positional embeddings   : {pos_embeddings.shape}\")\n",
    "print(f\"Final input embeddings  : {input_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Mean pooling to get one sentence-level vector per sentence\n",
    "sentence_vectors = input_embeddings.mean(dim=1)\n",
    "print(f\"Sentence vectors shape : {sentence_vectors.shape}  -> (80 x 64)\")\n",
    "print(f\"\\nVector sample (first 8 dims) : {sentence_vectors[0][:8].tolist()}\")\n",
    "print(f\"Sentence                     : {df['text'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Cosine similarity — same vs different category sentences\n",
    "import torch.nn.functional as F\n",
    "\n",
    "v1 = sentence_vectors[0]    # खेल\n",
    "v2 = sentence_vectors[1]    # खेल\n",
    "v3 = sentence_vectors[20]   # शिक्षा\n",
    "\n",
    "sim_same = F.cosine_similarity(v1.unsqueeze(0), v2.unsqueeze(0)).item()\n",
    "sim_diff = F.cosine_similarity(v1.unsqueeze(0), v3.unsqueeze(0)).item()\n",
    "\n",
    "print(f\"S1 : {df['text'][0]}\")\n",
    "print(f\"S2 : {df['text'][1]}\")\n",
    "print(f\"S3 : {df['text'][20]}\")\n",
    "print(f\"\\nSimilarity S1 vs S2 (same - खेल)    : {sim_same:.4f}\")\n",
    "print(f\"Similarity S1 vs S3 (diff - शिक्षा) : {sim_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Full Hindi Word Embedding pipeline summary\n",
    "print(\"=\" * 55)\n",
    "print(\"    HINDI WORD EMBEDDING PIPELINE SUMMARY\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Dataset          : hindi_dataset.csv\")\n",
    "print(f\"Shape            : {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "print(f\"Categories       : {sorted(df['category'].unique())}\")\n",
    "print(f\"Corpus size      : {len(raw_text):,} characters\")\n",
    "print(f\"Tokenizer        : SentencePiece BPE (Hindi-trained)\")\n",
    "print(f\"BPE Vocab size   : {VOCAB_SIZE}\")\n",
    "print(f\"Embedding dim    : {EMB_DIM}\")\n",
    "print(f\"Sequence length  : {MAX_LEN}\")\n",
    "print(f\"Token emb shape  : {token_embeddings.shape}\")\n",
    "print(f\"Final emb shape  : {input_embeddings.shape}\")\n",
    "print(f\"Sentence vectors : {sentence_vectors.shape}\")\n",
    "print(\"=\" * 55)\n",
    "print(\"Hindi embeddings ready!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
